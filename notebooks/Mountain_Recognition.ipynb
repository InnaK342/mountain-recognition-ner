{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Task: Mountain Name Recognition Using SpaCy\n",
        "The goal is to identify mountain names in sentences using spaCy. The steps involve dataset creation, model training, and testing."
      ],
      "metadata": {
        "id": "ke2kXydRIVJB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Required Libraries"
      ],
      "metadata": {
        "id": "woYiJDP9Iikt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBKmGCBRIUrW",
        "outputId": "fe135d9f-b9e3-4850-8256-7ff1038c8ad6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.2.0)\n",
            "Requirement already satisfied: seqeval in /usr/local/lib/python3.11/dist-packages (1.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.11)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.27.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.11/dist-packages (from seqeval) (1.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2024.12.14)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.11/dist-packages (0.4.3)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.2.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (1.26.4)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.9.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.27.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (24.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.16.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (17.0.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.11.11)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2024.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.18.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "# Installing necessary libraries\n",
        "!pip install datasets seqeval\n",
        "!pip install evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Import Libraries and Define Constants\n",
        "We import essential libraries and set up global constants like mountain names and API keys."
      ],
      "metadata": {
        "id": "02yvp9ZmI0Wb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import spacy\n",
        "import shutil\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import (\n",
        "    AutoTokenizer, AutoModelForTokenClassification,\n",
        "    DataCollatorForTokenClassification, TrainingArguments, Trainer\n",
        ")\n",
        "from datasets import Dataset\n",
        "from openai import OpenAI\n",
        "from spacy.tokens import DocBin"
      ],
      "metadata": {
        "id": "StNocebcInTJ"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List of mountain names for the task(for labeling the dataset)\n",
        "MOUNTAIN_NAMES = [\n",
        "    'Everest', 'Kilimanjaro', 'Vesuvius', 'Fuji', 'St. Helens', 'K2',\n",
        "    'Olympus', 'McKinley', 'Denali', 'Cook', 'Rainier', 'Kailash Mountain',\n",
        "    'Rocky Mountains', 'Andes Mountain range', 'Blanc', 'Hengshan',\n",
        "    'Appalachian Mountains', 'Eiger', 'Elbrus', 'Popa', 'Lemmon', 'Robson',\n",
        "    'Rushmore', 'El Capitan', 'Huangshan'\n",
        "]"
      ],
      "metadata": {
        "id": "OLardGsKI6MP"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Dataset Generation Using OpenAI GPT\n",
        "Using OpenAI's GPT, generate synthetic sentences containing mountain names. This helps in creating a labeled dataset."
      ],
      "metadata": {
        "id": "qQwJs-E1JF3C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# OpenAI API initialization\n",
        "client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
        "def generate_mountain_data_via_chatgpt(prompt, num_samples=10, temperature=1.0):\n",
        "    \"\"\"\n",
        "    Generates mountain-related sentences using GPT-based generation.\n",
        "\n",
        "    Args:\n",
        "        prompt (str): The prompt for generating sentences.\n",
        "        num_samples (int): Number of sentence samples to generate.\n",
        "        temperature (float): Sampling temperature for GPT.\n",
        "\n",
        "    Returns:\n",
        "        list: Generated sentences.\n",
        "    \"\"\"\n",
        "    responses = []\n",
        "    for _ in range(num_samples):\n",
        "        response = client.chat.completions.create(\n",
        "            messages=[\n",
        "                {\"role\": \"user\", \"content\": prompt},\n",
        "            ],\n",
        "            model=\"gpt-4\",\n",
        "            temperature=temperature,\n",
        "        )\n",
        "        response_text = response.choices[0].message.content\n",
        "        sentences = response_text.split('\\n')\n",
        "        sentences_cleaned = [re.sub(r'^\\d+\\.\\s*', '', sentence) for sentence in sentences]\n",
        "        responses.extend(sentences_cleaned)\n",
        "    return responses\n",
        "\n",
        "# Generating and Saving Data\n",
        "prompt = \"Generate 10 different sentences that include the name of a mountain. Each sentence should be unique and describe a different aspect of the mountain or related topic.\"\n",
        "generated_texts = generate_mountain_data_via_chatgpt(prompt, num_samples=5)\n",
        "df = pd.DataFrame(generated_texts, columns=[\"sentence\"])\n",
        "df.to_csv('mountains.csv', index=False)"
      ],
      "metadata": {
        "id": "FGdTbSLoJA_I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Load and Process Dataset\n",
        "The dataset `mountains.csv` contains sentences mentioning mountain names. It was generated in a previous step. Now, we will load the dataset and process it to label mountain names within the sentences."
      ],
      "metadata": {
        "id": "0XPPlqJQJv1v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = \"mountains.csv\"\n",
        "# Read the dataset into a DataFrame\n",
        "df = pd.read_csv(dataset_path, index_col=0)\n",
        "# Display the first few rows to verify the structure\n",
        "print(\"Dataset preview:\")\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8qtRhLzJxOA",
        "outputId": "dd171465-9d8b-45f7-aadf-bd786352029f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset preview:\n",
            "                                            sentence\n",
            "0  \"The glistening snowcaps of Mount Everest towe...\n",
            "1  \"Hikers come from all over the world to tackle...\n",
            "2  \"Mount Vesuvius looms over the city of Pompeii...\n",
            "3  \"The sunlight reflecting off Mount Fuji's sere...\n",
            "4  \"Geologists are continuously monitoring the vo...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def label_sentences(sentences, mountain_names):\n",
        "    \"\"\"\n",
        "    Labels sentences by marking mountain names.\n",
        "\n",
        "    Args:\n",
        "        sentences (list): List of sentences to label.\n",
        "        mountain_names (list): List of mountain names to detect.\n",
        "\n",
        "    Returns:\n",
        "        list: Labeled sentences.\n",
        "    \"\"\"\n",
        "    labeled_sentences = []\n",
        "    for sentence in sentences:\n",
        "        words = re.findall(r'\\b\\w+\\b', sentence)\n",
        "        labeled_words = []\n",
        "        for word in words:\n",
        "            if any(mountain_name.lower() == word.lower() for mountain_name in mountain_names):\n",
        "                labeled_words.append('MOUNTAIN')\n",
        "            else:\n",
        "                labeled_words.append('O')\n",
        "        labeled_sentences.append(labeled_words)\n",
        "    return labeled_sentences"
      ],
      "metadata": {
        "id": "7llcc7_7KG2-"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['labels'] = label_sentences(df['sentence'], MOUNTAIN_NAMES)\n",
        "print(\"Labeled sentences added to the dataframe.\")\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "hEOOMasuLrUw",
        "outputId": "1993aa20-35ea-4d73-bdab-c076fa3d4200"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Labeled sentences added to the dataframe.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            sentence  \\\n",
              "0  \"The glistening snowcaps of Mount Everest towe...   \n",
              "1  \"Hikers come from all over the world to tackle...   \n",
              "2  \"Mount Vesuvius looms over the city of Pompeii...   \n",
              "3  \"The sunlight reflecting off Mount Fuji's sere...   \n",
              "4  \"Geologists are continuously monitoring the vo...   \n",
              "\n",
              "                                              labels  \n",
              "0  [O, O, O, O, O, MOUNTAIN, O, O, O, O, O, O, O,...  \n",
              "1  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, MOU...  \n",
              "2  [O, MOUNTAIN, O, O, O, O, O, O, O, O, O, O, O,...  \n",
              "3  [O, O, O, O, O, MOUNTAIN, O, O, O, O, O, O, O,...  \n",
              "4      [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-06b750fe-b54e-4516-bb59-5de64dd5954b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\"The glistening snowcaps of Mount Everest towe...</td>\n",
              "      <td>[O, O, O, O, O, MOUNTAIN, O, O, O, O, O, O, O,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"Hikers come from all over the world to tackle...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, MOU...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\"Mount Vesuvius looms over the city of Pompeii...</td>\n",
              "      <td>[O, MOUNTAIN, O, O, O, O, O, O, O, O, O, O, O,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"The sunlight reflecting off Mount Fuji's sere...</td>\n",
              "      <td>[O, O, O, O, O, MOUNTAIN, O, O, O, O, O, O, O,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\"Geologists are continuously monitoring the vo...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-06b750fe-b54e-4516-bb59-5de64dd5954b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-06b750fe-b54e-4516-bb59-5de64dd5954b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-06b750fe-b54e-4516-bb59-5de64dd5954b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7e1c920c-6387-4a74-af9e-64bb17b76790\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7e1c920c-6387-4a74-af9e-64bb17b76790')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7e1c920c-6387-4a74-af9e-64bb17b76790 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 50,\n  \"fields\": [\n    {\n      \"column\": \"sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 50,\n        \"samples\": [\n          \"As we explored the dense foliage at the foothills of the Rocky Mountains, the echo of distant waterfalls lured us into their mesmerizing beauty.\",\n          \"The rugged paths leading to the Mount Elbrus summit present an exhilarating blend of ice, rock and extreme weather, making it a challenging escapade for experienced climbers.\",\n          \"The Everest being the highest peak in the world, sparks the adventurous spirit in many climbers who wish to conquer it. \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"labels\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Split Dataset into Training and Evaluation Sets\n",
        "Split the labeled dataset into training and evaluation sets to prepare for model training and validation.\n"
      ],
      "metadata": {
        "id": "Q24RHnzHMWpt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_dataset(df, test_size=0.2):\n",
        "    \"\"\"\n",
        "    Splits the dataset into training and evaluation sets.\n",
        "\n",
        "    Args:\n",
        "        df (DataFrame): The dataset.\n",
        "        test_size (float): Proportion of the dataset to include in the evaluation split.\n",
        "\n",
        "    Returns:\n",
        "        tuple: Training and evaluation datasets.\n",
        "    \"\"\"\n",
        "    return train_test_split(df, test_size=test_size, random_state=42)\n",
        "\n",
        "# Split the dataset\n",
        "train_sentences, eval_sentences = split_dataset(df)\n",
        "print(\"Training and evaluation sets prepared.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rDmk_phLx4s",
        "outputId": "8d9d787b-6c36-413b-895b-d08360f3c75d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training and evaluation sets prepared.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Convert Data to SpaCy Format\n",
        "Prepare the dataset in a format suitable for training a SpaCy Named Entity Recognition (NER) model.\n"
      ],
      "metadata": {
        "id": "-8aUKhv8Mscw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_spacy_format(df, label=\"MOUNTAIN\"):\n",
        "    \"\"\"\n",
        "    Converts data into SpaCy format.\n",
        "\n",
        "    Args:\n",
        "        df (DataFrame): Data to convert.\n",
        "        label (str): Label for entities.\n",
        "\n",
        "    Returns:\n",
        "        list: Data in SpaCy format.\n",
        "    \"\"\"\n",
        "    spacy_data = []\n",
        "    for _, row in df.iterrows():\n",
        "        text = row[\"sentence\"]\n",
        "        entities = []\n",
        "        for match in re.finditer(r'\\b(?:' + '|'.join(map(re.escape, MOUNTAIN_NAMES)) + r')\\b', text, re.IGNORECASE):\n",
        "            entities.append((match.start(), match.end(), label))\n",
        "        spacy_data.append((text, {\"entities\": entities}))\n",
        "    return spacy_data\n",
        "\n",
        "# Convert train and eval datasets to SpaCy format\n",
        "train_data_spacy = convert_to_spacy_format(pd.DataFrame(train_sentences, columns=df.columns))\n",
        "eval_data_spacy = convert_to_spacy_format(pd.DataFrame(eval_sentences, columns=df.columns))\n",
        "print(\"Data converted to SpaCy format.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "amnufFJVMmPt",
        "outputId": "0d60d70f-1172-4422-d614-e4f5926f0c03"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data converted to SpaCy format.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Save Data in SpaCy Format\n",
        "Save the SpaCy-formatted training and evaluation datasets for use in training the NER model.\n"
      ],
      "metadata": {
        "id": "p4SYnTtqMxIQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_to_spacy(data, output_path, nlp):\n",
        "    \"\"\"\n",
        "    Saves data in SpaCy format.\n",
        "\n",
        "    Args:\n",
        "        data (list): Data to save.\n",
        "        output_path (str): File path to save data.\n",
        "        nlp: SpaCy language model.\n",
        "    \"\"\"\n",
        "    from spacy.tokens import DocBin\n",
        "    db = DocBin()\n",
        "    for text, annotations in data:\n",
        "        doc = nlp.make_doc(text)\n",
        "        entities = annotations[\"entities\"]\n",
        "        spans = [doc.char_span(start, end, label=label) for start, end, label in entities]\n",
        "        spans = [span for span in spans if span is not None]\n",
        "        doc.ents = spans\n",
        "        db.add(doc)\n",
        "    db.to_disk(output_path)\n",
        "\n",
        "# Save the datasets\n",
        "nlp = spacy.blank(\"en\")\n",
        "save_to_spacy(train_data_spacy, \"train.spacy\", nlp)\n",
        "save_to_spacy(eval_data_spacy, \"eval.spacy\", nlp)\n",
        "print(\"SpaCy datasets saved.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_TybRoxTMvhw",
        "outputId": "4d520550-4b70-46c4-9f9d-786d960eaf2b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SpaCy datasets saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Train SpaCy NER Model\n",
        "Train a Named Entity Recognition (NER) model using the prepared SpaCy datasets.\n"
      ],
      "metadata": {
        "id": "wFuHKfkDM3_V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy init config config.cfg --lang en --pipeline ner --optimize efficiency\n",
        "!python -m spacy train config.cfg --output ./output --paths.train ./train.spacy --paths.dev ./eval.spacy\n",
        "print(\"SpaCy NER model training completed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Buhpyc8QM2p1",
        "outputId": "b16edd1d-9e54-4a34-d525-f3eb9f7ef0a5"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;3m⚠ To generate a more effective transformer-based config (GPU-only),\n",
            "install the spacy-transformers package and re-run this command. The config\n",
            "generated now does not use transformers.\u001b[0m\n",
            "\u001b[38;5;4mℹ Generated config template specific for your use case\u001b[0m\n",
            "- Language: en\n",
            "- Pipeline: ner\n",
            "- Optimize for: efficiency\n",
            "- Hardware: CPU\n",
            "- Transformer: None\n",
            "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
            "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
            "config.cfg\n",
            "You can now add your data and train your pipeline:\n",
            "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n",
            "\u001b[38;5;2m✔ Created output directory: output\u001b[0m\n",
            "\u001b[38;5;4mℹ Saving to output directory: output\u001b[0m\n",
            "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
            "\u001b[38;5;4mℹ To switch to GPU 0, use the option: --gpu-id 0\u001b[0m\n",
            "\u001b[1m\n",
            "=========================== Initializing pipeline ===========================\u001b[0m\n",
            "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
            "\u001b[1m\n",
            "============================= Training pipeline =============================\u001b[0m\n",
            "\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'ner']\u001b[0m\n",
            "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
            "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
            "---  ------  ------------  --------  ------  ------  ------  ------\n",
            "  0       0          0.00     34.17    0.00    0.00    0.00    0.00\n",
            " 21     200         10.64    745.38   82.35  100.00   70.00    0.82\n",
            " 48     400          0.00      0.00   82.35  100.00   70.00    0.82\n",
            " 81     600          0.00      0.00   82.35  100.00   70.00    0.82\n",
            "121     800          0.00      0.00   82.35  100.00   70.00    0.82\n",
            "171    1000          0.00      0.00   82.35  100.00   70.00    0.82\n",
            "234    1200          0.00      0.00   82.35  100.00   70.00    0.82\n",
            "300    1400          0.00      0.00   82.35  100.00   70.00    0.82\n",
            "397    1600          0.00      0.00   82.35  100.00   70.00    0.82\n",
            "497    1800          0.00      0.00   82.35  100.00   70.00    0.82\n",
            "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
            "output/model-last\n",
            "SpaCy NER model training completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Test the Trained SpaCy Model\n",
        "Load the trained SpaCy NER model and test it on sample sentences."
      ],
      "metadata": {
        "id": "xWEyflHCNPVZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the trained model\n",
        "nlp_trained = spacy.load(\"./output/model-best\")\n",
        "\n",
        "def test_spacy_model(texts, model):\n",
        "    \"\"\"\n",
        "    Tests the SpaCy model with sample texts.\n",
        "\n",
        "    Args:\n",
        "        texts (list): List of texts to test.\n",
        "        model: Trained SpaCy model.\n",
        "    \"\"\"\n",
        "    for text in texts:\n",
        "        doc = model(text)\n",
        "        if doc.ents:\n",
        "          for ent in doc.ents:\n",
        "              print(f\"Entity: {ent.text}, Label: {ent.label_}\")\n",
        "        else:\n",
        "          print(f\"No mountain names found in: \\\"{text}\\\"\")\n",
        "\n",
        "\n",
        "# Test the trained model\n",
        "sample_texts = [\n",
        "    \"Everest is one of the tallest mountains in the world.\",\n",
        "    \"Mount Kilimanjaro is a dormant volcano located in Tanzania.\",\n",
        "    \"Mount Fuji in Japan is an active volcano and a cultural icon.\",\n",
        "    \"The Appalachian Mountains span multiple states in the eastern United States.\",\n",
        "    \"Rocky Mountains are a major mountain range in North America.\",\n",
        "    \"Huangshan, also known as Yellow Mountain, is famous for its scenic beauty in China.\",\n",
        "    \"Table Mountain offers stunning views of Cape Town in South Africa.\",\n",
        "    \"The Andes is the longest mountain range in the world.\",\n",
        "    \"This is a simple sentence without any mountain names.\",\n",
        "    \"A random sentence about hiking trails and beautiful landscapes.\",\n",
        "    \"The tallest peak in Antarctica is Mount Vinson.\",\n",
        "    \"Denali, formerly known as Mount McKinley, is the highest mountain in North America.\",\n",
        "    \"Mont Blanc is the highest mountain in the Alps and Western Europe.\",\n",
        "    \"A sentence without any significant geographical names.\"\n",
        "]\n",
        "\n",
        "test_spacy_model(sample_texts, nlp_trained)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIw9yjIGM7id",
        "outputId": "523444ba-adb9-4e94-929e-d4e674202304"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entity: Everest, Label: MOUNTAIN\n",
            "Entity: Kilimanjaro, Label: MOUNTAIN\n",
            "Entity: Fuji, Label: MOUNTAIN\n",
            "Entity: Appalachian Mountains, Label: MOUNTAIN\n",
            "Entity: Rocky Mountains, Label: MOUNTAIN\n",
            "Entity: Huangshan, Label: MOUNTAIN\n",
            "Entity: Yellow Mountain, Label: MOUNTAIN\n",
            "Entity: Table Mountain, Label: MOUNTAIN\n",
            "Entity: Cape Town, Label: MOUNTAIN\n",
            "No mountain names found in: \"The Andes is the longest mountain range in the world.\"\n",
            "No mountain names found in: \"This is a simple sentence without any mountain names.\"\n",
            "No mountain names found in: \"A random sentence about hiking trails and beautiful landscapes.\"\n",
            "Entity: Vinson, Label: MOUNTAIN\n",
            "Entity: Denali, Label: MOUNTAIN\n",
            "Entity: McKinley, Label: MOUNTAIN\n",
            "Entity: Blanc, Label: MOUNTAIN\n",
            "No mountain names found in: \"A sentence without any significant geographical names.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Results Analysis of the SpaCy NER Model\n",
        "\n",
        "**Test Results:**\n",
        "\n",
        "1. **Identified Correct Entities:**\n",
        "   - The model correctly identified various mountain names such as:\n",
        "     - *Everest* (Label: MOUNTAIN)\n",
        "     - *Kilimanjaro* (Label: MOUNTAIN)\n",
        "     - *Fuji* (Label: MOUNTAIN)\n",
        "     - *Appalachian Mountains* (Label: MOUNTAIN)\n",
        "     - *Rocky Mountains* (Label: MOUNTAIN)\n",
        "     - *Huangshan* (Label: MOUNTAIN)\n",
        "     - *Yellow Mountain* (Label: MOUNTAIN)\n",
        "     - *Table Mountain* (Label: MOUNTAIN)\n",
        "     - *Vinson* (Label: MOUNTAIN)\n",
        "     - *Denali* (Label: MOUNTAIN)\n",
        "     - *McKinley* (Label: MOUNTAIN)\n",
        "     - *Blanc* (Label: MOUNTAIN)\n",
        "\n",
        "2. **Missed Entities:**\n",
        "   - The model failed to recognize the mountain name in sentences such as:\n",
        "     - *The Andes is the longest mountain range in the world.*\n",
        "   - Possible reasons:\n",
        "     - Insufficient training examples for *Andes*.\n",
        "     - Variance in phrasing not covered in training.\n",
        "\n",
        "3. **False Negatives:**\n",
        "   - Sentences without mountain names were correctly identified as having no entities.\n",
        "\n",
        "4. **Performance Overview:**\n",
        "   - Strengths:\n",
        "     - Successfully identifies most explicitly mentioned mountain names.\n",
        "     - Handles multi-word names well, e.g., *Yellow Mountain*.\n",
        "   - Weaknesses:\n",
        "     - Struggles with general phrases or less common mountains.\n",
        "\n",
        "**Suggestions for Improvement:**\n",
        "\n",
        "- **Expand Training Dataset:** Include more sentences with underrepresented mountains such as *Andes* and *Elbrus*.\n",
        "- **Augment Data:** Use paraphrasing to create diverse expressions of mountain mentions.\n",
        "- **Iterate Training:** Train with additional examples to improve recognition consistency.\n",
        "\n",
        "**Next Steps:**\n",
        "1. Review missed and misclassified examples for patterns.\n",
        "2. Augment training data to address weaknesses.\n",
        "3. Retrain and re-evaluate the model.\n"
      ],
      "metadata": {
        "id": "m0Hcs9REOmqi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Create a Compressed Archive of the Model\n",
        "\n",
        "To save trained SpaCy model as a compressed archive, we use the following code to package it into a `.tar.gz` file.\n"
      ],
      "metadata": {
        "id": "9QlU3wP9QHj4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a compressed archive of the model directory\n",
        "shutil.make_archive(\"spacy_model\", \"gztar\", \"./output\", \"model-best\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "7qGsIISjRN9M",
        "outputId": "767562eb-6686-4539-82c4-d5b3ced360aa"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/spacy_model.tar.gz'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    }
  ]
}